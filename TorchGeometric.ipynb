{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network with Pytorch Geometric\n",
    "\n",
    "In the last decade, Deep Learning approaches (e.g. Convolutional Neural Networks and Recurrent Neural Networks) allowed to achieve unprecedented performance on a broad range of problems coming from a variety of different fields (e.g. Computer Vision and Speech Recognition). Despite the results obtained, research on DL techniques has mainly focused so far on data defined on Euclidean domains (i.e. grids). Nonetheless, in a multitude of different fields, such as: Biology, Physics, Network Science, Recommender Systems and Computer Graphics; one may have to deal with data defined on non-Euclidean domains (i.e. graphs and manifolds). The adoption of Deep Learning in these particular fields has been lagging behind until very recently, primarily since the non-Euclidean nature of data makes the definition of basic operations (such as convolution) rather elusive. Geometric Deep Learning deals in this sense with the extension of Deep Learning techniques to graph/manifold structured data.\n",
    "This website represents a collection of materials in the field of Geometric Deep Learning. We collect workshops, tutorials, publications and code, that several differet researchers has produced in the last years. Our goal is to provide a general picture of this new and emerging field, which is rapidly developing in the scientific community, thanks to the broad applicability it presents.\n",
    "## Resources\n",
    "- https://arxiv.org/pdf/1706.02216.pdf\n",
    "- https://github.com/rusty1s/pytorch_geometric\n",
    "- https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\n",
    "- https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3\n",
    "- http://geometricdeeplearning.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph\n",
    "In Computer Science, a graph is a data structure consisting of two components, verticies and edges. A graph $G$ can be well described by the set of vertices $V$ and edges $E$ it contains.\n",
    "$$ G = (V,E) $$\n",
    "\n",
    "Edges can be directed or undirected. Vertices are usually called Nodes.\n",
    "![directed graph](http://think-like-a-git.net/assets/images2/directed-graph.png) ![undirected](http://think-like-a-git.net/assets/images2/undirected-graph.png)\n",
    "\n",
    "## Graph Neural Network\n",
    "Works on Graph Structure, each node in the graph is associated with a label and we would like to predict these labels  of the nodes. [First Graph Paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1015.7227&rep=rep1&type=pdf) where it was introduced.\n",
    "In the node classification problem setup, each node $\\nu$ is characterised by its feature $x_\\nu$ and associated ground truth label $t_\\nu$. If we have a prtially labeled graph, we would like to use the labeled nodes to predicte the labels for the unlabeled nodes. \n",
    "\n",
    "For partially labeled graph $G$, the goal is to use the labeled nodes to predict the unlabeled ones. It learns to represent each node with a $d$ dimensional vector (state) $h_\\nu$ with contains the information of its neighborhood. \n",
    "$$\\mathbf{h}_\\nu = f(\\mathbf{X}_\\nu, \\mathbf{X}_{co[\\nu]}, \\mathbf{h}_{ne[\\nu]}, \\mathbf{X}_{ne[\\nu]})$$\n",
    "$$\\mathbf{O}_\\nu = \\mathcal{g}(\\mathbf{h}_\\nu, \\mathbf{x}_\\nu)$$\n",
    "\n",
    "where $x_\\nu$, $x_{co[\\nu]}$,  $h_{ne[\\nu]}$, $x_{ne[\\nu]}$ are the features of $\\nu$, the features of its edges, the states, and the features of the nodes in the neighbourhood of $\\nu$, respectively. Since we are seeking a solution for $h_\\nu$, using [Banach fixed point theorm](https://en.wikipedia.org/wiki/Fixed-point_theorem), namely $\\exists$ solution which $x=f(x)$.\n",
    "\n",
    "Rewriting the above  equation as an iterative update process, which is called __message passing__ or __neighbourhood aggregation__:\n",
    "$$ \\mathbf{H}^{t+1} = F(\\mathbf{H}^t, \\mathbf{X})$$\n",
    "\n",
    "Where $\\mathbf{H}$ and $\\mathbf{X}$ denote the concatenation of all $h$ and $x$. $\\mathbf{H}^t$ denotes the $t$-th iteration of $\\mathbf{H}$. \n",
    "\n",
    "$\\mathcal{f}$ and $\\mathcal{g}$ can be interpreted as the feedfoward neural networks. Assuming for each node $\\nu$ there is target $t_\\nu$ the loss can be written as follow:\n",
    "$$\\text{loss} = \\sum_{i=1}^p(\\mathbf{t}_i-\\mathbf{o}_i)$$\n",
    "where $p$ is the number of supervised nodes (see [Graph Neural Networks](https://arxiv.org/pdf/1812.08434.pdf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE (Graph SAmple and aggreGatE)\n",
    "![graph](images/graphsage-d.png)\n",
    "Unlike embedding approaches that are based on matrix factorization,we leverage node features (e.g., text attributes, node profile information, node degrees) in order tolearn an embedding function that generalizes to unseen nodes. By incorporating node features in the learning algorithm, we simultaneously learn the topological structure of each node’s neighborhood as well as the distribution of node features in the neighborhood.  While we focus on feature-rich graphs (e.g., citation data with text attributes, biological data with functional/molecular markers), our approach can also make use of structural features that are present in all graphs (e.g., node degrees).\n",
    "\n",
    "To learn embedding for each node in an inductive way: [Inductive Representation Learning on Large Graphs](https://arxiv.org/pdf/1706.02216.pdf)\n",
    "![graphsage](images/graphsage.png) we represent each node as an aggregation of its neighbourhood. \n",
    "\n",
    "\n",
    "$$ \\mathbf{h}^k_{\\mathcal{N}(\\nu)} \\leftarrow \\text{AGGREGATE}_k ({\\mathbf{h}^{k-1}_u, \\forall u \\in \\mathcal{N}(\\nu)})$$\n",
    "\n",
    "$$ \\mathbf{h}^k_\\nu \\leftarrow \\sigma(\\mathbf{W}^k . \\text{CONCAT}(\\mathbf{h}^{k-1}_\\nu, \\mathbf{h}^k_{\\mathcal{N}(\\nu)}))  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[3, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example Graph](images/example_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)\n",
    "\n",
    "edge_index = torch.tensor([[0, 2, 1, 0, 3],\n",
    "                           [3, 1, 0, 1, 2]], dtype=torch.long)\n",
    "#connect node 0 => 3, 2 => 1, 1 => 0, 0 => 1, 3 => 2\n",
    "\n",
    "\n",
    "data = Data(x=x, y=y, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 5], x=[4, 2], y=[4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_1.pt', 'data_2.pt', ...]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass \n",
    "    \n",
    "    def process(self):\n",
    "        i = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            data = Data(...)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                 continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                 data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, ops.join(self.processed_dir, 'data_{}.pt'.format(i)))\n",
    "            i += 1\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibrahim/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   0                         1  \\\n",
      "session_id                         1                         1   \n",
      "timestamp   2014-04-07T10:51:09.277Z  2014-04-07T10:54:09.868Z   \n",
      "item_id                         2053                      2052   \n",
      "category                           0                         0   \n",
      "\n",
      "                                   2                         3  \\\n",
      "session_id                         1                         1   \n",
      "timestamp   2014-04-07T10:54:46.998Z  2014-04-07T10:57:00.306Z   \n",
      "item_id                         2054                      9876   \n",
      "category                           0                         0   \n",
      "\n",
      "                                   4  \n",
      "session_id                         2  \n",
      "timestamp   2014-04-07T13:56:37.614Z  \n",
      "item_id                        19448  \n",
      "category                           0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/yoochoose-clicks.dat', header=None)\n",
    "df.columns=['session_id','timestamp','item_id','category']\n",
    "\n",
    "buy_df = pd.read_csv('data/yoochoose-buys.dat', header=None)\n",
    "buy_df.columns=['session_id','timestamp','item_id','price','quantity']\n",
    "\n",
    "item_encoder = LabelEncoder()\n",
    "df['item_id'] = item_encoder.fit_transform(df.item_id)\n",
    "print(df.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id    1000000\n",
       "timestamp     3570054\n",
       "item_id         35508\n",
       "category          238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#randomly sample a couple of them\n",
    "sampled_session_id = np.random.choice(df.session_id.unique(), 1000000, replace=False)\n",
    "df = df.loc[df.session_id.isin(sampled_session_id)]\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02T13:17:46.940Z</td>\n",
       "      <td>28989</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02T13:26:02.515Z</td>\n",
       "      <td>35310</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02T13:30:12.318Z</td>\n",
       "      <td>43178</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>2014-04-06T11:26:24.127Z</td>\n",
       "      <td>9613</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>2014-04-06T11:28:54.654Z</td>\n",
       "      <td>9613</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                 timestamp  item_id category  label\n",
       "10           3  2014-04-02T13:17:46.940Z    28989        0  False\n",
       "11           3  2014-04-02T13:26:02.515Z    35310        0  False\n",
       "12           3  2014-04-02T13:30:12.318Z    43178        0  False\n",
       "21           9  2014-04-06T11:26:24.127Z     9613        0  False\n",
       "22           9  2014-04-06T11:28:54.654Z     9613        0  False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.session_id.isin(buy_df.session_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "class YooChooseBinaryDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(YooChooseBinaryDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        print(self.processed_dir)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data/yoochoose_click_binary_1M_sess.dataset']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "\n",
    "        # process by session_id\n",
    "        grouped = df.groupby('session_id')\n",
    "        for session_id, group in tqdm(grouped):\n",
    "            sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
    "            group = group.reset_index(drop=True)\n",
    "            group['sess_item_id'] = sess_item_id\n",
    "            node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
    "\n",
    "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "            target_nodes = group.sess_item_id.values[1:]\n",
    "            source_nodes = group.sess_item_id.values[:-1]\n",
    "\n",
    "            edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "            x = node_features\n",
    "\n",
    "            y = torch.FloatTensor([group.label.values[0]])\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [40:29<00:00, 411.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "./processed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800000, 100000, 100000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = YooChooseBinaryDataset('')\n",
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:800000]\n",
    "val_dataset = dataset[800000:900000]\n",
    "test_dataset = dataset[900000:]\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$\n",
    "\\begin{algorithm}\n",
    "\\caption{My algorithm}\\label{euclid}\n",
    "\\begin{algorithmic}[1]\n",
    "\\Procedure{MyProcedure}{}\n",
    "\\State $\\textit{stringlen} \\gets \\text{length of }\\textit{string}$\n",
    "\\State $i \\gets \\textit{patlen}$\n",
    "\\BState \\emph{top}:\n",
    "\\If {$i > \\textit{stringlen}$} \\Return false\n",
    "\\EndIf\n",
    "\\State $j \\gets \\textit{patlen}$\n",
    "\\BState \\emph{loop}:\n",
    "\\If {$\\textit{string}(i) = \\textit{path}(j)$}\n",
    "\\State $j \\gets j-1$.\n",
    "\\State $i \\gets i-1$.\n",
    "\\State \\textbf{goto} \\emph{loop}.\n",
    "\\State \\textbf{close};\n",
    "\\EndIf\n",
    "\\State $i \\gets i+\\max(\\textit{delta}_1(\\textit{string}(i)),\\textit{delta}_2(j))$.\n",
    "\\State \\textbf{goto} \\emph{top}.\n",
    "\\EndProcedure\n",
    "\\end{algorithmic}\n",
    "\\end{algorithm}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
